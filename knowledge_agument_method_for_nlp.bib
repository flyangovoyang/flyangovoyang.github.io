@inproceedings{zhang2019ernie,
  title={ERNIE: Enhanced Language Representation with Informative Entities},
  author={Zhang, Zhengyan and Han, Xu and Liu, Zhiyuan and Jiang, Xin and Sun, Maosong and Liu, Qun},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={1441--1451},
  year={2019}
}

@inproceedings{peters2019knowledge,
  title={Knowledge Enhanced Contextual Word Representations},
  author={Peters, Matthew E and Neumann, Mark and Logan, Robert and Schwartz, Roy and Joshi, Vidur and Singh, Sameer and Smith, Noah A},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={43--54},
  year={2019}
}

@inproceedings{liu2020k,
  title={K-bert: Enabling language representation with knowledge graph},
  author={Liu, Weijie and Zhou, Peng and Zhao, Zhe and Wang, Zhiruo and Ju, Qi and Deng, Haotang and Wang, Ping},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={03},
  pages={2901--2908},
  year={2020}
}

@article{zhang2022survey,
  title={A survey of multi-task learning in natural language processing: Regarding task relatedness and training methods},
  author={Zhang, Zhihan and Yu, Wenhao and Yu, Mengxia and Guo, Zhichun and Jiang, Meng},
  journal={arXiv preprint arXiv:2204.03508},
  year={2022}
}

@inproceedings{yu2020identifying,
  title={Identifying referential intention with heterogeneous contexts},
  author={Yu, Wenhao and Yu, Mengxia and Zhao, Tong and Jiang, Meng},
  booktitle={Proceedings of The Web Conference 2020},
  pages={962--972},
  year={2020}
}

@article{wei2021knowledge,
  title={Knowledge enhanced pretrained language models: A compreshensive survey},
  author={Wei, Xiaokai and Wang, Shen and Zhang, Dejiao and Bhatia, Parminder and Arnold, Andrew},
  journal={arXiv preprint arXiv:2110.08455},
  year={2021}
}

@article{yang2021survey,
  title={A survey of knowledge enhanced pre-trained models},
  author={Yang, Jian and Xiao, Gang and Shen, Yulong and Jiang, Wei and Hu, Xinyu and Zhang, Ying and Peng, Jinghui},
  journal={arXiv preprint arXiv:2110.00269},
  year={2021}
}

@inproceedings{wang2021retrieval,
  title={Retrieval Enhanced Model for Commonsense Generation},
  author={Wang, Han and Liu, Yang and Zhu, Chenguang and Shou, Linjun and Gong, Ming and Xu, Yichong and Zeng, Michael},
  booktitle={Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021},
  pages={3056--3062},
  year={2021}
}

@inproceedings{xu2021fusing,
  title={Fusing Context Into Knowledge Graph for Commonsense Question Answering},
  author={Xu, Yichong and Zhu, Chenguang and Xu, Ruochen and Liu, Yang and Zeng, Michael and Huang, Xuedong},
  booktitle={Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021},
  pages={1201--1207},
  year={2021}
}

@inproceedings{liu2021kg,
  title={Kg-bart: Knowledge graph-augmented bart for generative commonsense reasoning},
  author={Liu, Ye and Wan, Yao and He, Lifang and Peng, Hao and Philip, S Yu},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={7},
  pages={6418--6425},
  year={2021}
}

@inproceedings{yu2022jaket,
  title={Jaket: Joint pre-training of knowledge graph and language understanding},
  author={Yu, Donghan and Zhu, Chenguang and Yang, Yiming and Zeng, Michael},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={10},
  pages={11630--11638},
  year={2022}
}

@inproceedings{fan2020enhanced,
  title={An Enhanced Knowledge Injection Model for Commonsense Generation},
  author={Fan, Zhihao and Gong, Yeyun and Wei, Zhongyu and Wang, Siyuan and Huang, Yameng and Jiao, Jian and Huang, Xuan-Jing and Duan, Nan and Zhang, Ruofei},
  booktitle={Proceedings of the 28th International Conference on Computational Linguistics},
  pages={2014--2025},
  year={2020}
}

@article{guan2020knowledge,
  title={A knowledge-enhanced pretraining model for commonsense story generation},
  author={Guan, Jian and Huang, Fei and Zhao, Zhihao and Zhu, Xiaoyan and Huang, Minlie},
  journal={Transactions of the Association for Computational Linguistics},
  volume={8},
  pages={93--108},
  year={2020},
  publisher={MIT Press}
}

@article{yu2022survey,
  title={A survey of knowledge-enhanced text generation},
  author={Yu, Wenhao and Zhu, Chenguang and Li, Zaitang and Hu, Zhiting and Wang, Qingyun and Ji, Heng and Jiang, Meng},
  journal={ACM Computing Surveys (CSUR)},
  year={2022},
  publisher={ACM New York, NY}
}

@article{lewis2020retrieval,
  title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020}
}

@inproceedings{ji2020language,
  title={Language Generation with Multi-Hop Reasoning on Commonsense Knowledge Graph},
  author={Ji, Haozhe and Ke, Pei and Huang, Shaohan and Wei, Furu and Zhu, Xiaoyan and Huang, Minlie},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={725--736},
  year={2020}
}

@inproceedings{lv2020graph,
  title={Graph-based reasoning over heterogeneous external knowledge for commonsense question answering},
  author={Lv, Shangwen and Guo, Daya and Xu, Jingjing and Tang, Duyu and Duan, Nan and Gong, Ming and Shou, Linjun and Jiang, Daxin and Cao, Guihong and Hu, Songlin},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={05},
  pages={8449--8456},
  year={2020}
}

@inproceedings{fevry2020entities,
  title={Entities as Experts: Sparse Memory Access with Entity Supervision},
  author={F{\'e}vry, Thibault and Soares, Livio Baldini and Fitzgerald, Nicholas and Choi, Eunsol and Kwiatkowski, Tom},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={4937--4951},
  year={2020}
}

@article{xiong2020pretrained,
  title={Pretrained Encyclopedia: Weakly Supervised Knowledge-Pretrained Language Model},
  author={Xiong, Wenhan and Du, Jingfei and Wang, William Yang and Stoyanov, Veselin},
  year={2020}
}

@inproceedings{shen2020exploiting,
  title={Exploiting Structured Knowledge in Text via Graph-Guided Representation Learning},
  author={Shen, Tao and Mao, Yi and He, Pengcheng and Long, Guodong and Trischler, Adam and Chen, Weizhu},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={8980--8994},
  year={2020}
}

@inproceedings{zeng2020tri,
  title={Tri-Train: Automatic Pre-Fine Tuning between Pre-Training and Fine-Tuning for SciNER},
  author={Zeng, Qingkai and Yu, Wenhao and Yu, Mengxia and Jiang, Tianwen and Weninger, Tim and Jiang, Meng},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2020},
  pages={4778--4787},
  year={2020}
}

@inproceedings{yu2022dict,
  title={Dict-BERT: Enhancing Language Model Pre-training with Dictionary},
  author={Yu, Wenhao and Zhu, Chenguang and Fang, Yuwei and Yu, Donghan and Wang, Shuohang and Xu, Yichong and Zeng, Michael and Jiang, Meng},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2022},
  pages={1907--1918},
  year={2022}
}

@inproceedings{zhang2020grounded,
  title={Grounded Conversation Generation as Guided Traverses in Commonsense Knowledge Graphs},
  author={Zhang, Houyu and Liu, Zhenghao and Xiong, Chenyan and Liu, Zhiyuan},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={2031--2043},
  year={2020}
}

@article{sun2019ernie,
  title={Ernie: Enhanced representation through knowledge integration},
  author={Sun, Yu and Wang, Shuohuan and Li, Yukun and Feng, Shikun and Chen, Xuyi and Zhang, Han and Tian, Xin and Zhu, Danxiang and Tian, Hao and Wu, Hua},
  journal={arXiv preprint arXiv:1904.09223},
  year={2019}
}

@article{wang2021kepler,
  title={KEPLER: A Unified Model for Knowledge Embedding and Pre-trained Language Representation},
  author={Wang, Xiaozhi and Gao, Tianyu and Zhu, Zhaocheng and Zhang, Zhengyan and Liu, Zhiyuan and Li, Juanzi and Tang, Jian},
  journal={Transactions of the Association for Computational Linguistics},
  volume={9},
  pages={176--194},
  year={2021}
}

@inproceedings{guan2019story,
  title={Story ending generation with incremental encoding and commonsense knowledge},
  author={Guan, Jian and Wang, Yansen and Huang, Minlie},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={6473--6480},
  year={2019}
}

@inproceedings{ding2019cognitive,
  title={Cognitive Graph for Multi-Hop Reading Comprehension at Scale},
  author={Ding, Ming and Zhou, Chang and Chen, Qibin and Yang, Hongxia and Tang, Jie},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={2694--2703},
  year={2019}
}

@inproceedings{ma2019towards,
  title={Towards Generalizable Neuro-Symbolic Systems for Commonsense Question Answering},
  author={Ma, Kaixin and Francis, Jonathan and Lu, Quanyang and Nyberg, Eric and Oltramari, Alessandro},
  booktitle={Proceedings of the First Workshop on Commonsense Inference in Natural Language Processing},
  pages={22--32},
  year={2019}
}

@inproceedings{zhou2018commonsense,
  title={Commonsense knowledge aware conversation generation with graph attention.},
  author={Zhou, Hao and Young, Tom and Huang, Minlie and Zhao, Haizhou and Xu, Jingfang and Zhu, Xiaoyan},
  booktitle={IJCAI},
  pages={4623--4629},
  year={2018}
}